# 批量同步性能验证

本目录包含用于验证批量同步性能提升的脚本。

## 脚本说明

### 1. 快速验证（推荐）

**脚本**: `quick_verify_batch_sync.py`

快速测试批量同步功能是否正常工作，测试 10 只股票。

```bash
# 运行快速验证
uv run python scripts/quick_verify_batch_sync.py
```

**输出示例**:
```
============================================================
快速验证批量同步功能
============================================================

配置:
  测试日期: 2026-02-08
  测试股票数: 10
  批量大小: 100
  并发数: 10
  连接池大小: 5

[1/3] 获取股票列表...
  ✓ 获取到 10 只股票: 600519.SH, 000001.SZ, ...

[2/3] 运行批量同步...
[批量同步] 开始：2026-02-08，共 10 只股票，批量大小=100，并发数=10
[批量同步] Batch 1/1 完成：成功 10/10，耗时 2.3s
[批量同步] 完成：成功 10 只，失败 0 只，总耗时 2.3s

[3/3] 结果:
  ✓ 成功: 10 只
  ⏱️  耗时: 2.35 秒
  📊 平均: 0.235 秒/只

推算全量同步 8000 只股票:
  预计耗时: 31.3 分钟 (0.52 小时)

============================================================
✅ 批量同步功能正常
============================================================
```

---

### 2. 性能对比验证

**脚本**: `verify_batch_sync_performance.py`

对比串行同步和批量同步的性能差异。

```bash
# 测试 50 只股票（默认）
uv run python scripts/verify_batch_sync_performance.py

# 测试 100 只股票
uv run python scripts/verify_batch_sync_performance.py --stock-count 100

# 指定测试日期
uv run python scripts/verify_batch_sync_performance.py --date 2026-02-07

# 跳过串行测试（节省时间）
uv run python scripts/verify_batch_sync_performance.py --skip-serial
```

**输出示例**:
```
============================================================
批量同步性能验证
============================================================
测试日期: 2026-02-08
测试股票数: 50
批量大小: 100
并发数: 10
连接池大小: 5

正在获取股票列表...
✓ 获取到 50 只股票

============================================================
测试 1: 串行同步（旧方式）
============================================================
  进度: 10/50 (20.0%)
  进度: 20/50 (40.0%)
  ...

结果:
  成功: 50 只
  失败: 0 只
  耗时: 125.34 秒
  平均: 2.507 秒/只

============================================================
测试 2: 批量并发同步（新方式）
============================================================
[批量同步] 开始：2026-02-08，共 50 只股票，批量大小=100，并发数=10
[批量同步] Batch 1/1 完成：成功 50/50，耗时 15.2s
[批量同步] 完成：成功 50 只，失败 0 只，总耗时 15.2s

结果:
  成功: 50 只
  失败: 0 只
  耗时: 15.23 秒
  平均: 0.305 秒/只

============================================================
性能对比
============================================================

串行同步: 125.34 秒
批量同步: 15.23 秒
性能提升: 8.23x
节省时间: 110.11 秒 (87.8%)

推算全量同步 8000 只股票:
  串行方式: 334.2 分钟 (5.57 小时)
  批量方式: 40.6 分钟 (0.68 小时)
  节省时间: 293.6 分钟

============================================================
验证完成
============================================================
```

---

## 运行前提

1. **数据库已初始化**
   ```bash
   uv run alembic upgrade head
   ```

2. **股票列表已同步**
   ```bash
   uv run python -m app.data.cli sync-stocks
   ```

3. **环境变量已配置**
   - 确保 `.env` 文件中配置了 `DATABASE_URL`
   - BaoStock API 可访问（无需 API Key）

---

## 配置调优

根据验证结果，可以调整 `.env` 中的配置参数：

```bash
# 批量同步配置
DAILY_SYNC_BATCH_SIZE=100        # 每批股票数（建议 50-200）
DAILY_SYNC_CONCURRENCY=10        # 并发数（建议 5-20）

# 连接池配置
BAOSTOCK_POOL_SIZE=5             # 连接池大小（建议 3-10）
BAOSTOCK_POOL_TIMEOUT=30.0       # 获取连接超时（秒）
BAOSTOCK_SESSION_TTL=3600.0      # 会话生存时间（秒）
```

**调优建议**:
- 如果网络稳定，可以增加 `DAILY_SYNC_CONCURRENCY` 到 15-20
- 如果遇到限流，降低 `DAILY_SYNC_CONCURRENCY` 到 5-8
- `BAOSTOCK_POOL_SIZE` 应该 >= `DAILY_SYNC_CONCURRENCY` / 2

---

## 故障排查

### 问题 1: 连接超时
```
TimeoutError: 连接池获取超时（30.0s）
```
**解决**: 增加 `BAOSTOCK_POOL_SIZE` 或降低 `DAILY_SYNC_CONCURRENCY`

### 问题 2: API 限流
```
DataSourceError: BaoStock query failed: 请求过于频繁
```
**解决**: 降低 `DAILY_SYNC_CONCURRENCY` 或增加 `BAOSTOCK_RETRY_INTERVAL`

### 问题 3: 数据库连接池耗尽
```
asyncpg.exceptions.TooManyConnectionsError
```
**解决**: 增加 `DB_POOL_SIZE` 或降低 `DAILY_SYNC_CONCURRENCY`

---

## 预期性能

基于设计目标：

| 股票数量 | 串行同步 | 批量同步 | 性能提升 |
|---------|---------|---------|---------|
| 100 只  | ~4 分钟  | ~30 秒   | 8x      |
| 1000 只 | ~40 分钟 | ~5 分钟  | 8x      |
| 8000 只 | ~5 小时  | ~40 分钟 | 7.5x    |

实际性能取决于：
- 网络速度
- BaoStock API 响应时间
- 数据库写入性能
- 配置参数
