## Context

当前系统的盘后链路在每个交易日 15:30 触发，执行流程为：交易日校验 → 日线同步 → 技术指标计算 → 缓存刷新 → 策略管道。但存在以下问题：

1. **数据延迟问题**：BaoStock 数据源在 15:30 时可能尚未更新当日数据，导致同步失败
2. **缺乏重试机制**：如果数据未就绪，任务直接失败，需要手动重新触发
3. **缺乏监控报警**：数据同步失败时无法及时发现和处理

**技术背景**：
- 现有调度器使用 APScheduler，支持 cron 任务和动态任务管理
- Redis 已部署并用于缓存，可复用于状态管理
- 盘后链路函数 `run_post_market_chain()` 已实现完整的数据同步流程
- 数据管理器 `DataManager` 提供 `is_trade_day()` 方法判断交易日

**约束条件**：
- V1 阶段不引入新的外部依赖
- 通知报警 V1 仅记录日志，V2 再接入实际通知服务
- 状态管理使用 Redis，避免新增数据库表

## Goals / Non-Goals

**Goals:**
- 实现智能数据嗅探机制，轻量级检测数据是否就绪（查询 5-10 只样本股票）
- 实现自动重试机制，数据未就绪时每 15 分钟嗅探一次，直到数据就绪或超时
- 实现超时报警，18:00 仍无数据时发送报警通知
- 实现任务状态管理，避免重复执行和跟踪同步进度
- 替换现有盘后链路任务，统一入口

**Non-Goals:**
- 不改变现有盘后链路的执行逻辑（复用 `run_post_market_chain()`）
- 不处理多数据源切换逻辑（保持现有 primary/backup 机制）
- 不实现实时监控面板（V2 功能）
- 不接入实际通知服务（V1 仅记录日志）

## Decisions

### 决策 1：数据嗅探策略

**选择**：查询 5-10 只流动性好的大盘股（如茅台、平安银行等），如果 ≥80% 的样本股有当日数据，则认为数据已就绪。

**理由**：
- 查询开销小（只查 5-10 只股票，而非全部 8000+ 只）
- 准确性高（大盘股数据更新最快，代表性强）
- 单次嗅探耗时 < 100ms，不影响系统性能

**替代方案**：
- ❌ 查询所有股票：开销太大，单次嗅探可能需要数秒
- ❌ 查询固定 1 只股票：准确性不足，可能误判
- ❌ 调用数据源 API 检查：增加 API 调用次数，且 BaoStock 无此接口

### 决策 2：任务状态管理

**选择**：使用 Redis 存储任务状态，Key 设计为 `sync_status:{date}`、`probe_count:{date}`、`probe_job_id:{date}`，TTL 设置为 7 天。

**理由**：
- Redis 已部署，无需新增依赖
- 内存操作，性能高
- TTL 自动清理，无需手动维护
- 支持原子操作（INCR、SET NX 等），避免并发问题

**替代方案**：
- ❌ 新增数据库表：增加数据库负担，且状态数据不需要持久化
- ❌ 内存变量：服务重启后丢失，无法跨进程共享
- ❌ 文件存储：并发控制复杂，性能差

**状态流转**：
```
pending → probing → syncing → completed
                 ↓
              failed (18:00 超时)
```

### 决策 3：调度器集成方式

**选择**：替换现有盘后链路任务，使用新的 `auto_update_job` 任务（每日 15:30 触发），保留 `run_post_market_chain()` 函数供调用。

**理由**：
- 统一入口，避免重复执行
- 自动更新任务包含原有盘后链路的所有功能
- 新增智能嗅探和报警能力
- 向后兼容，`run_post_market_chain()` 仍可手动调用

**替代方案**：
- ❌ 保留原任务，新增嗅探任务：可能导致重复执行，需要复杂的互斥逻辑
- ❌ 修改原任务逻辑：代码耦合度高，不利于维护

### 决策 4：嗅探任务管理

**选择**：使用 APScheduler 的动态任务管理，在数据未就绪时添加嗅探任务（每 15 分钟触发），数据就绪或超时后移除任务。

**理由**：
- APScheduler 支持动态添加/移除任务
- 嗅探任务独立于主任务，互不干扰
- 可以灵活控制嗅探频率和超时时间

**实现细节**：
- 嗅探任务 ID：`probe_and_sync_{date}`
- 触发间隔：15 分钟（可配置）
- 超时时间：18:00（可配置）
- 停止条件：数据就绪、超时、或任务已完成

### 决策 5：通知报警实现

**选择**：V1 阶段仅记录 ERROR 级别日志，V2 再接入企业微信/钉钉/邮件等通知服务。

**理由**：
- V1 快速上线，满足基本监控需求
- 日志可以通过日志收集系统（如 ELK）进行监控和报警
- 预留接口，V2 可以无缝接入实际通知服务

**接口设计**：
```python
class NotificationManager:
    async def send(
        self,
        level: NotificationLevel,
        title: str,
        message: str,
        metadata: dict | None = None,
    ) -> None:
        """发送通知（V1 仅记录日志，V2 接入实际服务）"""
```

## Risks / Trade-offs

### 风险 1：数据源延迟超过 18:00

**风险**：如果 BaoStock 数据源延迟超过 18:00，系统会发送超时报警并停止嗅探，导致当日数据无法同步。

**缓解措施**：
- 超时时间可配置（默认 18:00），可根据实际情况调整
- 超时后不阻止手动触发同步
- V2 可以增加次日补齐逻辑

### 风险 2：嗅探样本股票不具代表性

**风险**：如果选择的样本股票数据更新较慢，可能导致误判（实际大部分股票已有数据，但样本股票还没有）。

**缓解措施**：
- 选择流动性好的大盘股作为样本（茅台、平安银行等）
- 样本股票可配置，可根据实际情况调整
- 阈值设置为 80%，允许少量样本股票数据延迟

### 风险 3：Redis 不可用

**风险**：如果 Redis 不可用，任务状态管理失效，可能导致重复执行或无法跟踪进度。

**缓解措施**：
- Redis 连接失败时记录警告日志
- 状态管理失败时降级为无状态模式（每次都尝试同步，依赖交易日判断）
- V2 可以增加状态持久化到数据库的降级方案

### Trade-off 1：嗅探频率 vs API 调用

**选择**：每 15 分钟嗅探一次

**权衡**：
- ✅ 优点：减少数据库查询次数，避免频繁嗅探
- ⚠️ 缺点：数据就绪后可能需要等待最多 15 分钟才能同步

**结论**：15 分钟已足够，盘后数据同步不需要实时性。

### Trade-off 2：样本股票数量 vs 准确性

**选择**：5-10 只样本股票

**权衡**：
- ✅ 优点：查询开销小，单次嗅探 < 100ms
- ⚠️ 缺点：样本数量少，可能存在误判

**结论**：5-10 只大盘股已足够代表整体数据更新情况，误判概率低。

## Migration Plan

### 部署步骤

1. **代码部署**：
   - 创建新模块：`app/data/probe.py`、`app/scheduler/state.py`、`app/scheduler/auto_update.py`、`app/notification/__init__.py`
   - 修改 `app/scheduler/core.py`：注册自动更新任务，移除原有盘后链路任务
   - 修改 `app/config.py`：新增配置项
   - 修改 `.env.example`：新增环境变量示例
   - 重启服务

2. **配置更新**：
   - 复制 `.env.example` 中的新配置项到 `.env`
   - 根据实际情况调整配置值（嗅探间隔、超时时间、样本股票等）

3. **验证**：
   - 检查日志中是否有 "注册任务：自动数据更新" 记录
   - 等待 15:30 自动触发，观察日志输出
   - 检查 Redis 中是否有状态记录：`redis-cli KEYS sync_status:*`

### 回滚策略

如果出现问题，可以：
1. 回滚代码到上一个版本
2. 恢复原有盘后链路任务配置
3. Redis 状态数据会自动过期（TTL 7 天），无需手动清理

### 兼容性

- ✅ 向后兼容：`run_post_market_chain()` 函数保持不变，仍可手动调用
- ✅ 配置兼容：新增配置项有默认值，不影响现有配置
- ✅ 数据兼容：无数据库表变更，Redis 状态数据独立存储

## Open Questions

无待解决问题。所有技术决策已明确，可以直接进入实施阶段。
